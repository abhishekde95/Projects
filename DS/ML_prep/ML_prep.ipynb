{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd   \n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_bias_term(X: np.ndarray) -> np.ndarray:\n",
    "    n = X.shape[0]\n",
    "    return np.hstack([np.ones((n, 1)), X])\n",
    "    \n",
    "\n",
    "# using matrix multiplication\n",
    "class CustomLinearRegression():\n",
    "    def __init__(self) -> None:\n",
    "        self.W = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y) -> None:\n",
    "        \"\"\" \n",
    "        y = X * W    \n",
    "        W = inv(X_t * X) * X_t * Y  \n",
    "        \"\"\"\n",
    "            \n",
    "        # Add bias\n",
    "        X = _add_bias_term(X)\n",
    "        self.W = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "        return None\n",
    "        \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        X = _add_bias_term(X)\n",
    "        return X @ self.W \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class CustomLinearRegressionGD():\n",
    "    \n",
    "    def __init__(self, L2_regul: float = 0.1):\n",
    "        self.L2_regul = L2_regul\n",
    "        self.W = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X: np.ndarray, Y: np.ndarray, lr: float = 0.01, num_iters: int = 1000) -> None:\n",
    "        \n",
    "        # Add checks\n",
    "        if (len(X) != len(Y)) or len(X) ==0:\n",
    "            raise ValueError(\"The number of samples in X and Y should be the same.\")\n",
    "        \n",
    "        if (num_iters<=0) or (lr<=0):\n",
    "            raise ValueError(\"Number of iterations and learning rate should be positive.\")\n",
    "        \n",
    "        # Add bias\n",
    "        X = _add_bias_term(X)\n",
    "        \n",
    "        # Gradient decsent\n",
    "        self.W = np.zeros(X.shape[1])\n",
    "        for i in range(num_iters):\n",
    "            y_pred = np.dot(X, self.W)\n",
    "            \n",
    "            # cost\n",
    "            loss = np.sum((y_pred - y)**2) + (self.L2_regul * np.sum(self.W ** 2))\n",
    "            \n",
    "            # Calculate gradient\n",
    "            gradient = 2 * np.dot(X.T, y_pred-y) + 2 * self.L2_regul * self.W\n",
    "            \n",
    "            # Update weights\n",
    "            self.W -= lr*gradient \n",
    "                        \n",
    "        \n",
    "        return None\n",
    "        \n",
    "        \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.dot(_add_bias_term(X), self.W)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 1. 2.]\n",
      "[35. 44.]\n"
     ]
    }
   ],
   "source": [
    "# Using the non gradient descent algorithm\n",
    "# Create example input data\n",
    "X = np.array([[2, 2], [4, 5], [7, 8]])\n",
    "y = np.array([9, 17, 26])\n",
    "\n",
    "# Fit linear regression model\n",
    "lr = CustomLinearRegression()\n",
    "lr.fit(X, y)\n",
    "print(lr.W) # [3. 1. 2.]\n",
    "\n",
    "# Make predictions on new data\n",
    "X_new = np.array([[10, 11], [13, 14]])\n",
    "y_pred = lr.predict(X_new)\n",
    "print(y_pred)  # Output: [43. 55.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.99964292 0.65345474]\n",
      "[2.65309766 3.3065524  3.96000714 4.61346188 5.26691662]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array([[1, 2, 3, 4, 5]]).T\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "lr = CustomLinearRegressionGD()\n",
    "lr.fit(X, y, lr=0.01, num_iters=10000)\n",
    "print(lr.W)  # Output: [ 1.99964292  0.65345474 ]\n",
    "y_pred = lr.predict(X)\n",
    "print(y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regresison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression():\n",
    "    \n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def fit() -> None:\n",
    "        \n",
    "        return None\n",
    "        \n",
    "        \n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "choice(a, size=None, replace=True, p=None)\n",
      "\n",
      "Generates a random sample from a given 1-D array\n",
      "\n",
      ".. versionadded:: 1.7.0\n",
      "\n",
      ".. note::\n",
      "    New code should use the `~numpy.random.Generator.choice`\n",
      "    method of a `~numpy.random.Generator` instance instead;\n",
      "    please see the :ref:`random-quick-start`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "a : 1-D array-like or int\n",
      "    If an ndarray, a random sample is generated from its elements.\n",
      "    If an int, the random sample is generated as if it were ``np.arange(a)``\n",
      "size : int or tuple of ints, optional\n",
      "    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "    ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "    single value is returned.\n",
      "replace : boolean, optional\n",
      "    Whether the sample is with or without replacement. Default is True,\n",
      "    meaning that a value of ``a`` can be selected multiple times.\n",
      "p : 1-D array-like, optional\n",
      "    The probabilities associated with each entry in a.\n",
      "    If not given, the sample assumes a uniform distribution over all\n",
      "    entries in ``a``.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "samples : single item or ndarray\n",
      "    The generated random samples\n",
      "\n",
      "Raises\n",
      "------\n",
      "ValueError\n",
      "    If a is an int and less than zero, if a or p are not 1-dimensional,\n",
      "    if a is an array-like of size 0, if p is not a vector of\n",
      "    probabilities, if a and p have different lengths, or if\n",
      "    replace=False and the sample size is greater than the population\n",
      "    size\n",
      "\n",
      "See Also\n",
      "--------\n",
      "randint, shuffle, permutation\n",
      "random.Generator.choice: which should be used in new code\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Setting user-specified probabilities through ``p`` uses a more general but less\n",
      "efficient sampler than the default. The general sampler produces a different sample\n",
      "than the optimized sampler even if each element of ``p`` is 1 / len(a).\n",
      "\n",
      "Sampling random rows from a 2-D array is not possible with this function,\n",
      "but is possible with `Generator.choice` through its ``axis`` keyword.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Generate a uniform random sample from np.arange(5) of size 3:\n",
      "\n",
      ">>> np.random.choice(5, 3)\n",
      "array([0, 3, 4]) # random\n",
      ">>> #This is equivalent to np.random.randint(0,5,3)\n",
      "\n",
      "Generate a non-uniform random sample from np.arange(5) of size 3:\n",
      "\n",
      ">>> np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "array([3, 3, 0]) # random\n",
      "\n",
      "Generate a uniform random sample from np.arange(5) of size 3 without\n",
      "replacement:\n",
      "\n",
      ">>> np.random.choice(5, 3, replace=False)\n",
      "array([3,1,0]) # random\n",
      ">>> #This is equivalent to np.random.permutation(np.arange(5))[:3]\n",
      "\n",
      "Generate a non-uniform random sample from np.arange(5) of size\n",
      "3 without replacement:\n",
      "\n",
      ">>> np.random.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "array([2, 3, 0]) # random\n",
      "\n",
      "Any of the above can be repeated with an arbitrary array-like\n",
      "instead of just integers. For instance:\n",
      "\n",
      ">>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
      ">>> np.random.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])\n",
      "array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'], # random\n",
      "      dtype='<U11')\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "np.random.choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Matrix or vector norm.\n",
      "\n",
      "This function is able to return one of eight different matrix norms,\n",
      "or one of an infinite number of vector norms (described below), depending\n",
      "on the value of the ``ord`` parameter.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x : array_like\n",
      "    Input array.  If `axis` is None, `x` must be 1-D or 2-D, unless `ord`\n",
      "    is None. If both `axis` and `ord` are None, the 2-norm of\n",
      "    ``x.ravel`` will be returned.\n",
      "ord : {non-zero int, inf, -inf, 'fro', 'nuc'}, optional\n",
      "    Order of the norm (see table under ``Notes``). inf means numpy's\n",
      "    `inf` object. The default is None.\n",
      "axis : {None, int, 2-tuple of ints}, optional.\n",
      "    If `axis` is an integer, it specifies the axis of `x` along which to\n",
      "    compute the vector norms.  If `axis` is a 2-tuple, it specifies the\n",
      "    axes that hold 2-D matrices, and the matrix norms of these matrices\n",
      "    are computed.  If `axis` is None then either a vector norm (when `x`\n",
      "    is 1-D) or a matrix norm (when `x` is 2-D) is returned. The default\n",
      "    is None.\n",
      "\n",
      "    .. versionadded:: 1.8.0\n",
      "\n",
      "keepdims : bool, optional\n",
      "    If this is set to True, the axes which are normed over are left in the\n",
      "    result as dimensions with size one.  With this option the result will\n",
      "    broadcast correctly against the original `x`.\n",
      "\n",
      "    .. versionadded:: 1.10.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "n : float or ndarray\n",
      "    Norm of the matrix or vector(s).\n",
      "\n",
      "See Also\n",
      "--------\n",
      "scipy.linalg.norm : Similar function in SciPy.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "For values of ``ord < 1``, the result is, strictly speaking, not a\n",
      "mathematical 'norm', but it may still be useful for various numerical\n",
      "purposes.\n",
      "\n",
      "The following norms can be calculated:\n",
      "\n",
      "=====  ============================  ==========================\n",
      "ord    norm for matrices             norm for vectors\n",
      "=====  ============================  ==========================\n",
      "None   Frobenius norm                2-norm\n",
      "'fro'  Frobenius norm                --\n",
      "'nuc'  nuclear norm                  --\n",
      "inf    max(sum(abs(x), axis=1))      max(abs(x))\n",
      "-inf   min(sum(abs(x), axis=1))      min(abs(x))\n",
      "0      --                            sum(x != 0)\n",
      "1      max(sum(abs(x), axis=0))      as below\n",
      "-1     min(sum(abs(x), axis=0))      as below\n",
      "2      2-norm (largest sing. value)  as below\n",
      "-2     smallest singular value       as below\n",
      "other  --                            sum(abs(x)**ord)**(1./ord)\n",
      "=====  ============================  ==========================\n",
      "\n",
      "The Frobenius norm is given by [1]_:\n",
      "\n",
      "    :math:`||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}`\n",
      "\n",
      "The nuclear norm is the sum of the singular values.\n",
      "\n",
      "Both the Frobenius and nuclear norm orders are only defined for\n",
      "matrices and raise a ValueError when ``x.ndim != 2``.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] G. H. Golub and C. F. Van Loan, *Matrix Computations*,\n",
      "       Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from numpy import linalg as LA\n",
      ">>> a = np.arange(9) - 4\n",
      ">>> a\n",
      "array([-4, -3, -2, ...,  2,  3,  4])\n",
      ">>> b = a.reshape((3, 3))\n",
      ">>> b\n",
      "array([[-4, -3, -2],\n",
      "       [-1,  0,  1],\n",
      "       [ 2,  3,  4]])\n",
      "\n",
      ">>> LA.norm(a)\n",
      "7.745966692414834\n",
      ">>> LA.norm(b)\n",
      "7.745966692414834\n",
      ">>> LA.norm(b, 'fro')\n",
      "7.745966692414834\n",
      ">>> LA.norm(a, np.inf)\n",
      "4.0\n",
      ">>> LA.norm(b, np.inf)\n",
      "9.0\n",
      ">>> LA.norm(a, -np.inf)\n",
      "0.0\n",
      ">>> LA.norm(b, -np.inf)\n",
      "2.0\n",
      "\n",
      ">>> LA.norm(a, 1)\n",
      "20.0\n",
      ">>> LA.norm(b, 1)\n",
      "7.0\n",
      ">>> LA.norm(a, -1)\n",
      "-4.6566128774142013e-010\n",
      ">>> LA.norm(b, -1)\n",
      "6.0\n",
      ">>> LA.norm(a, 2)\n",
      "7.745966692414834\n",
      ">>> LA.norm(b, 2)\n",
      "7.3484692283495345\n",
      "\n",
      ">>> LA.norm(a, -2)\n",
      "0.0\n",
      ">>> LA.norm(b, -2)\n",
      "1.8570331885190563e-016 # may vary\n",
      ">>> LA.norm(a, 3)\n",
      "5.8480354764257312 # may vary\n",
      ">>> LA.norm(a, -3)\n",
      "0.0\n",
      "\n",
      "Using the `axis` argument to compute vector norms:\n",
      "\n",
      ">>> c = np.array([[ 1, 2, 3],\n",
      "...               [-1, 1, 4]])\n",
      ">>> LA.norm(c, axis=0)\n",
      "array([ 1.41421356,  2.23606798,  5.        ])\n",
      ">>> LA.norm(c, axis=1)\n",
      "array([ 3.74165739,  4.24264069])\n",
      ">>> LA.norm(c, ord=1, axis=1)\n",
      "array([ 6.,  6.])\n",
      "\n",
      "Using the `axis` argument to compute matrix norms:\n",
      "\n",
      ">>> m = np.arange(8).reshape(2,2,2)\n",
      ">>> LA.norm(m, axis=(1,2))\n",
      "array([  3.74165739,  11.22497216])\n",
      ">>> LA.norm(m[0, :, :]), LA.norm(m[1, :, :])\n",
      "(3.7416573867739413, 11.224972160321824)\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Desktop/Projects/.venv/lib/python3.8/site-packages/numpy/linalg/linalg.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "np.linalg.norm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "where(condition, [x, y], /)\n",
      "\n",
      "Return elements chosen from `x` or `y` depending on `condition`.\n",
      "\n",
      ".. note::\n",
      "    When only `condition` is provided, this function is a shorthand for\n",
      "    ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be\n",
      "    preferred, as it behaves correctly for subclasses. The rest of this\n",
      "    documentation covers only the case where all three arguments are\n",
      "    provided.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "condition : array_like, bool\n",
      "    Where True, yield `x`, otherwise yield `y`.\n",
      "x, y : array_like\n",
      "    Values from which to choose. `x`, `y` and `condition` need to be\n",
      "    broadcastable to some shape.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "out : ndarray\n",
      "    An array with elements from `x` where `condition` is True, and elements\n",
      "    from `y` elsewhere.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "choose\n",
      "nonzero : The function that is called when x and y are omitted\n",
      "\n",
      "Notes\n",
      "-----\n",
      "If all the arrays are 1-D, `where` is equivalent to::\n",
      "\n",
      "    [xv if c else yv\n",
      "     for c, xv, yv in zip(condition, x, y)]\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> a = np.arange(10)\n",
      ">>> a\n",
      "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      ">>> np.where(a < 5, a, 10*a)\n",
      "array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])\n",
      "\n",
      "This can be used on multidimensional arrays too:\n",
      "\n",
      ">>> np.where([[True, False], [True, True]],\n",
      "...          [[1, 2], [3, 4]],\n",
      "...          [[9, 8], [7, 6]])\n",
      "array([[1, 8],\n",
      "       [3, 4]])\n",
      "\n",
      "The shapes of x, y, and the condition are broadcast together:\n",
      "\n",
      ">>> x, y = np.ogrid[:3, :4]\n",
      ">>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast\n",
      "array([[10,  0,  0,  0],\n",
      "       [10, 11,  1,  1],\n",
      "       [10, 11, 12,  2]])\n",
      "\n",
      ">>> a = np.array([[0, 1, 2],\n",
      "...               [0, 2, 4],\n",
      "...               [0, 3, 6]])\n",
      ">>> np.where(a < 4, a, -1)  # -1 is broadcast\n",
      "array([[ 0,  1,  2],\n",
      "       [ 0,  2, -1],\n",
      "       [ 0,  3, -1]])\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "np.where?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "True if two arrays have the same shape and elements, False otherwise.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "a1, a2 : array_like\n",
      "    Input arrays.\n",
      "equal_nan : bool\n",
      "    Whether to compare NaN's as equal. If the dtype of a1 and a2 is\n",
      "    complex, values will be considered equal if either the real or the\n",
      "    imaginary component of a given value is ``nan``.\n",
      "\n",
      "    .. versionadded:: 1.19.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "b : bool\n",
      "    Returns True if the arrays are equal.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "allclose: Returns True if two arrays are element-wise equal within a\n",
      "          tolerance.\n",
      "array_equiv: Returns True if input arrays are shape consistent and all\n",
      "             elements equal.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> np.array_equal([1, 2], [1, 2])\n",
      "True\n",
      ">>> np.array_equal(np.array([1, 2]), np.array([1, 2]))\n",
      "True\n",
      ">>> np.array_equal([1, 2], [1, 2, 3])\n",
      "False\n",
      ">>> np.array_equal([1, 2], [1, 4])\n",
      "False\n",
      ">>> a = np.array([1, np.nan])\n",
      ">>> np.array_equal(a, a)\n",
      "False\n",
      ">>> np.array_equal(a, a, equal_nan=True)\n",
      "True\n",
      "\n",
      "When ``equal_nan`` is True, complex values with nan components are\n",
      "considered equal if either the real *or* the imaginary components are nan.\n",
      "\n",
      ">>> a = np.array([1 + 1j])\n",
      ">>> b = a.copy()\n",
      ">>> a.real = np.nan\n",
      ">>> b.imag = np.nan\n",
      ">>> np.array_equal(a, b, equal_nan=True)\n",
      "True\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Desktop/Projects/.venv/lib/python3.8/site-packages/numpy/core/numeric.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "np.array_equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        NoneType\n",
      "\u001b[0;31mString form:\u001b[0m None\n",
      "\u001b[0;31mDocstring:\u001b[0m   <no docstring>"
     ]
    }
   ],
   "source": [
    "np.newaxis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting=\"same_kind\")\n",
      "\n",
      "Join a sequence of arrays along an existing axis.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "a1, a2, ... : sequence of array_like\n",
      "    The arrays must have the same shape, except in the dimension\n",
      "    corresponding to `axis` (the first, by default).\n",
      "axis : int, optional\n",
      "    The axis along which the arrays will be joined.  If axis is None,\n",
      "    arrays are flattened before use.  Default is 0.\n",
      "out : ndarray, optional\n",
      "    If provided, the destination to place the result. The shape must be\n",
      "    correct, matching that of what concatenate would have returned if no\n",
      "    out argument were specified.\n",
      "dtype : str or dtype\n",
      "    If provided, the destination array will have this dtype. Cannot be\n",
      "    provided together with `out`.\n",
      "\n",
      "    .. versionadded:: 1.20.0\n",
      "\n",
      "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "    Controls what kind of data casting may occur. Defaults to 'same_kind'.\n",
      "\n",
      "    .. versionadded:: 1.20.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "res : ndarray\n",
      "    The concatenated array.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "ma.concatenate : Concatenate function that preserves input masks.\n",
      "array_split : Split an array into multiple sub-arrays of equal or\n",
      "              near-equal size.\n",
      "split : Split array into a list of multiple sub-arrays of equal size.\n",
      "hsplit : Split array into multiple sub-arrays horizontally (column wise).\n",
      "vsplit : Split array into multiple sub-arrays vertically (row wise).\n",
      "dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
      "stack : Stack a sequence of arrays along a new axis.\n",
      "block : Assemble arrays from blocks.\n",
      "hstack : Stack arrays in sequence horizontally (column wise).\n",
      "vstack : Stack arrays in sequence vertically (row wise).\n",
      "dstack : Stack arrays in sequence depth wise (along third dimension).\n",
      "column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "When one or more of the arrays to be concatenated is a MaskedArray,\n",
      "this function will return a MaskedArray object instead of an ndarray,\n",
      "but the input masks are *not* preserved. In cases where a MaskedArray\n",
      "is expected as input, use the ma.concatenate function from the masked\n",
      "array module instead.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> a = np.array([[1, 2], [3, 4]])\n",
      ">>> b = np.array([[5, 6]])\n",
      ">>> np.concatenate((a, b), axis=0)\n",
      "array([[1, 2],\n",
      "       [3, 4],\n",
      "       [5, 6]])\n",
      ">>> np.concatenate((a, b.T), axis=1)\n",
      "array([[1, 2, 5],\n",
      "       [3, 4, 6]])\n",
      ">>> np.concatenate((a, b), axis=None)\n",
      "array([1, 2, 3, 4, 5, 6])\n",
      "\n",
      "This function will not preserve masking of MaskedArray inputs.\n",
      "\n",
      ">>> a = np.ma.arange(3)\n",
      ">>> a[1] = np.ma.masked\n",
      ">>> b = np.arange(2, 5)\n",
      ">>> a\n",
      "masked_array(data=[0, --, 2],\n",
      "             mask=[False,  True, False],\n",
      "       fill_value=999999)\n",
      ">>> b\n",
      "array([2, 3, 4])\n",
      ">>> np.concatenate([a, b])\n",
      "masked_array(data=[0, 1, 2, 2, 3, 4],\n",
      "             mask=False,\n",
      "       fill_value=999999)\n",
      ">>> np.ma.concatenate([a, b])\n",
      "masked_array(data=[0, --, 2, 2, 3, 4],\n",
      "             mask=[False,  True, False, False, False, False],\n",
      "       fill_value=999999)\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "np.concatenate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    \n",
    "    def __init__(self, k, max_iterations=100, tol = 1e-4):\n",
    "        self.k = k\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tol = tol\n",
    "        self.cluster_assignments = np.nan\n",
    "        self.centroids = np.nan\n",
    "        \n",
    "        \n",
    "    def fit(self, X) -> None:\n",
    "        \n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.asarray(X)\n",
    "        \n",
    "        # Choose centroids\n",
    "        self.centroids = X[np.random.choice(X.shape[0], self.k, replace=False)]\n",
    "        \n",
    "        for iter in range(self.max_iterations):\n",
    "            # Assign clusters\n",
    "            distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n",
    "            cluster_assignments = np.argmin(distances, axis=1)\n",
    "                \n",
    "            # Update centroids\n",
    "            new_centroids = np.array([np.mean(X[np.where(np.array(cluster_assignments) ==j)], axis=0) for j in range(self.k)])                \n",
    "                \n",
    "            if np.linalg.norm(self.centroids - new_centroids) < self.tol:\n",
    "                break\n",
    "            \n",
    "            self.centroids = new_centroids\n",
    "            \n",
    "        self.cluster_assignments = cluster_assignments\n",
    "            \n",
    "        return None   \n",
    "         \n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Assign clusters\n",
    "        cluster_assignments = []\n",
    "        for i in range(len(X)):\n",
    "            distances = np.linalg.norm(X[i] - self.centroids, axis=1)\n",
    "            cluster_assignments.append(np.argmin(distances))\n",
    "            \n",
    "        return cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[-4.92465394 -5.00431652]\n",
      " [ 4.79985465  4.72403842]]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 50\n",
    "x1 = np.random.randn(num_samples,2) + 5\n",
    "x2 = np.random.randn(num_samples,2) - 5\n",
    "X = np.concatenate([x1,x2], axis=0)\n",
    "\n",
    "# Initialize the KMeans object with k=3\n",
    "kmeans = KMeans(k=2)\n",
    "\n",
    "# Fit the k-means model to the dataset\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the cluster assignments for the input dataset\n",
    "cluster_assignments = kmeans.predict(X)\n",
    "\n",
    "# Print the cluster assignments\n",
    "print(cluster_assignments)\n",
    "\n",
    "# Print the learned centroids\n",
    "print(kmeans.centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8.08594525,  9.22704964],\n",
       "        [ 1.43211325, -1.72891002]],\n",
       "\n",
       "       [[ 7.70136893,  9.41146569],\n",
       "        [ 1.04753693, -1.54449397]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = X[np.random.choice(X.shape[0], 2, replace=False)]\n",
    "X[:2, np.newaxis] - centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(np.linalg.norm(X[:, np.newaxis] - centroids, axis=2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Plot the data points with different colors based on their cluster assignments\n",
    "colors = ['r', 'b']\n",
    "for i in range(kmeans.k):\n",
    "    plt.scatter(X[np.where(np.array(cluster_assignments) == i)][:,0], \n",
    "                X[np.where(np.array(cluster_assignments) == i)][:,1], \n",
    "                color=colors[i], alpha = 0.2)\n",
    "\n",
    "# Plot the centroids as black circles\n",
    "plt.scatter(kmeans.centroids[:,0], kmeans.centroids[:,1], color='black', marker='+', s=200)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LinearSVC',\n",
       " 'LinearSVR',\n",
       " 'NuSVC',\n",
       " 'NuSVR',\n",
       " 'OneClassSVM',\n",
       " 'SVC',\n",
       " 'SVR',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_bounds',\n",
       " '_classes',\n",
       " '_liblinear',\n",
       " '_libsvm',\n",
       " '_libsvm_sparse',\n",
       " 'l1_min_c']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "dir(sklearn.svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BaseCrossValidator',\n",
       " 'BaseShuffleSplit',\n",
       " 'GridSearchCV',\n",
       " 'GroupKFold',\n",
       " 'GroupShuffleSplit',\n",
       " 'KFold',\n",
       " 'LearningCurveDisplay',\n",
       " 'LeaveOneGroupOut',\n",
       " 'LeaveOneOut',\n",
       " 'LeavePGroupsOut',\n",
       " 'LeavePOut',\n",
       " 'ParameterGrid',\n",
       " 'ParameterSampler',\n",
       " 'PredefinedSplit',\n",
       " 'RandomizedSearchCV',\n",
       " 'RepeatedKFold',\n",
       " 'RepeatedStratifiedKFold',\n",
       " 'ShuffleSplit',\n",
       " 'StratifiedGroupKFold',\n",
       " 'StratifiedKFold',\n",
       " 'StratifiedShuffleSplit',\n",
       " 'TimeSeriesSplit',\n",
       " 'ValidationCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__getattr__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_plot',\n",
       " '_search',\n",
       " '_split',\n",
       " '_validation',\n",
       " 'check_cv',\n",
       " 'cross_val_predict',\n",
       " 'cross_val_score',\n",
       " 'cross_validate',\n",
       " 'learning_curve',\n",
       " 'permutation_test_score',\n",
       " 'train_test_split',\n",
       " 'typing',\n",
       " 'validation_curve']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sklearn.model_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmake_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_informative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_redundant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_repeated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_clusters_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mflip_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclass_sep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhypercube\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Generate a random n-class classification problem.\n",
      "\n",
      "This initially creates clusters of points normally distributed (std=1)\n",
      "about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "class. It introduces interdependence between these features and adds\n",
      "various types of further noise to the data.\n",
      "\n",
      "Without shuffling, ``X`` horizontally stacks features in the following\n",
      "order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "linear combinations of the informative features, followed by ``n_repeated``\n",
      "duplicates, drawn randomly with replacement from the informative and\n",
      "redundant features. The remaining features are filled with random noise.\n",
      "Thus, without shuffling, all useful features are contained in the columns\n",
      "``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "\n",
      "Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_samples : int, default=100\n",
      "    The number of samples.\n",
      "\n",
      "n_features : int, default=20\n",
      "    The total number of features. These comprise ``n_informative``\n",
      "    informative features, ``n_redundant`` redundant features,\n",
      "    ``n_repeated`` duplicated features and\n",
      "    ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "    drawn at random.\n",
      "\n",
      "n_informative : int, default=2\n",
      "    The number of informative features. Each class is composed of a number\n",
      "    of gaussian clusters each located around the vertices of a hypercube\n",
      "    in a subspace of dimension ``n_informative``. For each cluster,\n",
      "    informative features are drawn independently from  N(0, 1) and then\n",
      "    randomly linearly combined within each cluster in order to add\n",
      "    covariance. The clusters are then placed on the vertices of the\n",
      "    hypercube.\n",
      "\n",
      "n_redundant : int, default=2\n",
      "    The number of redundant features. These features are generated as\n",
      "    random linear combinations of the informative features.\n",
      "\n",
      "n_repeated : int, default=0\n",
      "    The number of duplicated features, drawn randomly from the informative\n",
      "    and the redundant features.\n",
      "\n",
      "n_classes : int, default=2\n",
      "    The number of classes (or labels) of the classification problem.\n",
      "\n",
      "n_clusters_per_class : int, default=2\n",
      "    The number of clusters per class.\n",
      "\n",
      "weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
      "    The proportions of samples assigned to each class. If None, then\n",
      "    classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "    then the last class weight is automatically inferred.\n",
      "    More than ``n_samples`` samples may be returned if the sum of\n",
      "    ``weights`` exceeds 1. Note that the actual class proportions will\n",
      "    not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
      "\n",
      "flip_y : float, default=0.01\n",
      "    The fraction of samples whose class is assigned randomly. Larger\n",
      "    values introduce noise in the labels and make the classification\n",
      "    task harder. Note that the default setting flip_y > 0 might lead\n",
      "    to less than ``n_classes`` in y in some cases.\n",
      "\n",
      "class_sep : float, default=1.0\n",
      "    The factor multiplying the hypercube size.  Larger values spread\n",
      "    out the clusters/classes and make the classification task easier.\n",
      "\n",
      "hypercube : bool, default=True\n",
      "    If True, the clusters are put on the vertices of a hypercube. If\n",
      "    False, the clusters are put on the vertices of a random polytope.\n",
      "\n",
      "shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
      "    Shift features by the specified value. If None, then features\n",
      "    are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "\n",
      "scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
      "    Multiply features by the specified value. If None, then features\n",
      "    are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "    happens after shifting.\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Shuffle the samples and the features.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Determines random number generation for dataset creation. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "X : ndarray of shape (n_samples, n_features)\n",
      "    The generated samples.\n",
      "\n",
      "y : ndarray of shape (n_samples,)\n",
      "    The integer labels for class membership of each sample.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "make_blobs : Simplified variant.\n",
      "make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "the \"Madelon\" dataset.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "       selection benchmark\", 2003.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Desktop/Projects/.venv/lib/python3.8/site-packages/sklearn/datasets/_samples_generator.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "make_classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.02514259,  0.0291022 , -0.47494531, -0.11473644,  0.50498728,\n",
       "         0.08896214,  0.40498171, -0.65332923,  0.18645431, -0.66178646,\n",
       "        -0.07133524,  2.14394409,  1.76545424,  0.85243333,  0.63391902,\n",
       "         0.08714206, -0.79252074, -0.33450124,  0.86575519, -1.20029641],\n",
       "       [ 1.61371127,  0.65992405, -0.15005559, -1.22760782,  0.59740007,\n",
       "         0.86561977,  0.01557905,  0.12557645,  0.4535343 , -0.24415664,\n",
       "        -1.15806823,  0.32135722, -0.17307182,  0.96408717,  0.42192075,\n",
       "         0.96335953,  1.18947049,  1.37570681,  0.70117274, -0.2975635 ],\n",
       "       [ 0.16645221,  0.95057302,  1.42050425, -0.53099696, -0.62314053,\n",
       "        -2.25553963,  0.47141556, -0.57074629,  0.49245126,  0.28916864,\n",
       "        -0.27062383, -1.12272202, -0.83235557,  2.45530014,  0.38240975,\n",
       "        -1.69200458, -0.63773998,  1.18901653, -0.55547712, -0.63738713],\n",
       "       [ 0.69822331, -0.32066954,  1.7359638 , -0.53523521,  1.31739407,\n",
       "        -1.14658127, -0.48388583,  0.19791078,  0.39348539,  0.89519322,\n",
       "         0.85239186,  0.05963037, -0.651418  ,  0.6351718 , -0.64693678,\n",
       "        -1.10644979,  1.04955272, -0.68918782,  0.1975996 ,  2.07526087],\n",
       "       [ 0.17989415, -0.22210005,  0.10537551,  0.94077119, -0.98248739,\n",
       "         1.56010259,  0.31978193, -1.33402549,  1.39200229,  0.91831661,\n",
       "        -0.34898484, -0.98859111, -0.60136764, -1.5705006 , -1.10358932,\n",
       "         1.30373602, -0.98962814, -0.96834445, -0.22463315,  0.5500521 ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 20), (75, 20))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()),(\"svc\",  SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(svc__C=10).fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Construct a :class:`Pipeline` from the given estimators.\n",
      "\n",
      "This is a shorthand for the :class:`Pipeline` constructor; it does not\n",
      "require, and does not permit, naming the estimators. Instead, their names\n",
      "will be set to the lowercase of their types automatically.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "*steps : list of Estimator objects\n",
      "    List of the scikit-learn estimators that are chained together.\n",
      "\n",
      "memory : str or object with the joblib.Memory interface, default=None\n",
      "    Used to cache the fitted transformers of the pipeline. The last step\n",
      "    will never be cached, even if it is a transformer. By default, no\n",
      "    caching is performed. If a string is given, it is the path to the\n",
      "    caching directory. Enabling caching triggers a clone of the transformers\n",
      "    before fitting. Therefore, the transformer instance given to the\n",
      "    pipeline cannot be inspected directly. Use the attribute ``named_steps``\n",
      "    or ``steps`` to inspect estimators within the pipeline. Caching the\n",
      "    transformers is advantageous when fitting is time consuming.\n",
      "\n",
      "verbose : bool, default=False\n",
      "    If True, the time elapsed while fitting each step will be printed as it\n",
      "    is completed.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "p : Pipeline\n",
      "    Returns a scikit-learn :class:`Pipeline` object.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "Pipeline : Class for creating a pipeline of transforms with a final\n",
      "    estimator.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.naive_bayes import GaussianNB\n",
      ">>> from sklearn.preprocessing import StandardScaler\n",
      ">>> from sklearn.pipeline import make_pipeline\n",
      ">>> make_pipeline(StandardScaler(), GaussianNB(priors=None))\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gaussiannb', GaussianNB())])\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Desktop/Projects/.venv/lib/python3.8/site-packages/sklearn/pipeline.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "make_pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "result = np.dot(A, B)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "result = A @ B\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "trading"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
